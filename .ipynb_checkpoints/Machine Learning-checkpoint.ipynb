{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "427a7ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn) (3.0.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn) (1.0.2)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "8a21ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "36668a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "12119c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./Data/processed/train.csv\", sep = \"|\")\n",
    "test_df = pd.read_csv(\"./Data/processed/test.csv\", sep = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a89b6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_df['sentences'].values\n",
    "test_sentences  = test_df['sentences'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a1c99766",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_count_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "unigram_tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "\n",
    "bigram_count_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "bigram_tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "unig_count_wm = unigram_count_vectorizer.fit_transform(train_sentences)\n",
    "unig_tfidf_wm = unigram_tfidf_vectorizer.fit_transform(train_sentences)\n",
    "big_count_wm = bigram_count_vectorizer.fit_transform(train_sentences)\n",
    "big_tfidf_wm = bigram_tfidf_vectorizer.fit_transform(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "fc92e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tokens = count_vectorizer.get_feature_names_out()\n",
    "tfidf_tokens = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "504fca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countvect = pd.DataFrame(data = count_wm.toarray(), index = train_sentences, columns = count_tokens)\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = train_sentences,columns = tfidf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0476c399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "      <th>1983</th>\n",
       "      <th>20</th>\n",
       "      <th>2003</th>\n",
       "      <th>...</th>\n",
       "      <th>ồn_ào</th>\n",
       "      <th>ổ_cắm</th>\n",
       "      <th>ổn</th>\n",
       "      <th>ổn_thỏa</th>\n",
       "      <th>ổn_định</th>\n",
       "      <th>ủa</th>\n",
       "      <th>ủng_hộ</th>\n",
       "      <th>ức_chế</th>\n",
       "      <th>ứng_dụng</th>\n",
       "      <th>ứng_đáp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slide giáo_trình đầy_đủ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nhiệt_tình giảng_dạy gần_gũi với sinh_viên</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>đi học đầy_đủ full điểm chuyên cần</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chưa áp_dụng công_nghệ_thông_tin và các thiết_bị hỗ_trợ cho việc giảng_dạy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thầy giảng bài hay có nhiều bài_tập ví_dụ ngay trên lớp</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chỉ vì môn game mà em học hai lần mà không qua quả_thật em rất không hài_lòng vì những lý_do vô_cùng thiếu chuyên_nghiệp như thế này</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>em cảm_ơn cô nhiều</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>giao bài_tập quá nhiều</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>giáo_viên dạy dễ hiểu nhiệt_tình</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gói gọn doubledot hay tận_tình phù_hợp với mọi trình_độ cũng như nhu_cầu môn_học</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11426 rows × 3449 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    10  100  11  12  13  15  \\\n",
       "slide giáo_trình đầy_đủ                              0    0   0   0   0   0   \n",
       "nhiệt_tình giảng_dạy gần_gũi với sinh_viên           0    0   0   0   0   0   \n",
       "đi học đầy_đủ full điểm chuyên cần                   0    0   0   0   0   0   \n",
       "chưa áp_dụng công_nghệ_thông_tin và các thiết_b...   0    0   0   0   0   0   \n",
       "thầy giảng bài hay có nhiều bài_tập ví_dụ ngay ...   0    0   0   0   0   0   \n",
       "...                                                 ..  ...  ..  ..  ..  ..   \n",
       "chỉ vì môn game mà em học hai lần mà không qua ...   0    0   0   0   0   0   \n",
       "em cảm_ơn cô nhiều                                   0    0   0   0   0   0   \n",
       "giao bài_tập quá nhiều                               0    0   0   0   0   0   \n",
       "giáo_viên dạy dễ hiểu nhiệt_tình                     0    0   0   0   0   0   \n",
       "gói gọn doubledot hay tận_tình phù_hợp với mọi ...   0    0   0   0   0   0   \n",
       "\n",
       "                                                    19  1983  20  2003  ...  \\\n",
       "slide giáo_trình đầy_đủ                              0     0   0     0  ...   \n",
       "nhiệt_tình giảng_dạy gần_gũi với sinh_viên           0     0   0     0  ...   \n",
       "đi học đầy_đủ full điểm chuyên cần                   0     0   0     0  ...   \n",
       "chưa áp_dụng công_nghệ_thông_tin và các thiết_b...   0     0   0     0  ...   \n",
       "thầy giảng bài hay có nhiều bài_tập ví_dụ ngay ...   0     0   0     0  ...   \n",
       "...                                                 ..   ...  ..   ...  ...   \n",
       "chỉ vì môn game mà em học hai lần mà không qua ...   0     0   0     0  ...   \n",
       "em cảm_ơn cô nhiều                                   0     0   0     0  ...   \n",
       "giao bài_tập quá nhiều                               0     0   0     0  ...   \n",
       "giáo_viên dạy dễ hiểu nhiệt_tình                     0     0   0     0  ...   \n",
       "gói gọn doubledot hay tận_tình phù_hợp với mọi ...   0     0   0     0  ...   \n",
       "\n",
       "                                                    ồn_ào  ổ_cắm  ổn  ổn_thỏa  \\\n",
       "slide giáo_trình đầy_đủ                                 0      0   0        0   \n",
       "nhiệt_tình giảng_dạy gần_gũi với sinh_viên              0      0   0        0   \n",
       "đi học đầy_đủ full điểm chuyên cần                      0      0   0        0   \n",
       "chưa áp_dụng công_nghệ_thông_tin và các thiết_b...      0      0   0        0   \n",
       "thầy giảng bài hay có nhiều bài_tập ví_dụ ngay ...      0      0   0        0   \n",
       "...                                                   ...    ...  ..      ...   \n",
       "chỉ vì môn game mà em học hai lần mà không qua ...      0      0   0        0   \n",
       "em cảm_ơn cô nhiều                                      0      0   0        0   \n",
       "giao bài_tập quá nhiều                                  0      0   0        0   \n",
       "giáo_viên dạy dễ hiểu nhiệt_tình                        0      0   0        0   \n",
       "gói gọn doubledot hay tận_tình phù_hợp với mọi ...      0      0   0        0   \n",
       "\n",
       "                                                    ổn_định  ủa  ủng_hộ  \\\n",
       "slide giáo_trình đầy_đủ                                   0   0       0   \n",
       "nhiệt_tình giảng_dạy gần_gũi với sinh_viên                0   0       0   \n",
       "đi học đầy_đủ full điểm chuyên cần                        0   0       0   \n",
       "chưa áp_dụng công_nghệ_thông_tin và các thiết_b...        0   0       0   \n",
       "thầy giảng bài hay có nhiều bài_tập ví_dụ ngay ...        0   0       0   \n",
       "...                                                     ...  ..     ...   \n",
       "chỉ vì môn game mà em học hai lần mà không qua ...        0   0       0   \n",
       "em cảm_ơn cô nhiều                                        0   0       0   \n",
       "giao bài_tập quá nhiều                                    0   0       0   \n",
       "giáo_viên dạy dễ hiểu nhiệt_tình                          0   0       0   \n",
       "gói gọn doubledot hay tận_tình phù_hợp với mọi ...        0   0       0   \n",
       "\n",
       "                                                    ức_chế  ứng_dụng  ứng_đáp  \n",
       "slide giáo_trình đầy_đủ                                  0         0        0  \n",
       "nhiệt_tình giảng_dạy gần_gũi với sinh_viên               0         0        0  \n",
       "đi học đầy_đủ full điểm chuyên cần                       0         0        0  \n",
       "chưa áp_dụng công_nghệ_thông_tin và các thiết_b...       0         0        0  \n",
       "thầy giảng bài hay có nhiều bài_tập ví_dụ ngay ...       0         0        0  \n",
       "...                                                    ...       ...      ...  \n",
       "chỉ vì môn game mà em học hai lần mà không qua ...       0         0        0  \n",
       "em cảm_ơn cô nhiều                                       0         0        0  \n",
       "giao bài_tập quá nhiều                                   0         0        0  \n",
       "giáo_viên dạy dễ hiểu nhiệt_tình                         0         0        0  \n",
       "gói gọn doubledot hay tận_tình phù_hợp với mọi ...       0         0        0  \n",
       "\n",
       "[11426 rows x 3449 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5e74cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train =  unig_tfidf_wm \n",
    "y_train = train_df['sentiments'].values\n",
    "\n",
    "x_test = unigram_tfidf_vectorizer.transform(test_sentences)\n",
    "y_test = test_df['sentiments'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "6bdb77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "weights = [{0:1, 1: 1, 2:1}, {0:1, 1:5, 2:1}, {0:1, 1:10, 2:1}]\n",
    "# param_grid = {'C': [0.1, 1, 10],\n",
    "#               'gamma': [ 1],\n",
    "#               'kernel': ['linear', 'rbf'],\n",
    "#              'class_weight': weights}\n",
    "\n",
    "\n",
    "param_grid = {'C': [1],\n",
    "              'gamma': [ 1],\n",
    "              'kernel': ['rbf'],\n",
    "             'class_weight': [{0:1, 1:5, 2:1}]}\n",
    "\n",
    "\n",
    "svm_classifier = SVC(probability =True)\n",
    "\n",
    "svm_grid = GridSearchCV(svm_classifier, param_grid, cv = 5, verbose = 3\n",
    "                        , scoring='f1_weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "ede142b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END C=1, class_weight={0: 1, 1: 5, 2: 1}, gamma=1, kernel=rbf;, score=0.907 total time=  25.4s\n",
      "[CV 2/5] END C=1, class_weight={0: 1, 1: 5, 2: 1}, gamma=1, kernel=rbf;, score=0.901 total time=  25.4s\n",
      "[CV 3/5] END C=1, class_weight={0: 1, 1: 5, 2: 1}, gamma=1, kernel=rbf;, score=0.914 total time=  24.9s\n",
      "[CV 4/5] END C=1, class_weight={0: 1, 1: 5, 2: 1}, gamma=1, kernel=rbf;, score=0.910 total time=  25.2s\n",
      "[CV 5/5] END C=1, class_weight={0: 1, 1: 5, 2: 1}, gamma=1, kernel=rbf;, score=0.887 total time=  24.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(probability=True),\n",
       "             param_grid={'C': [1], 'class_weight': [{0: 1, 1: 5, 2: 1}],\n",
       "                         'gamma': [1], 'kernel': ['rbf']},\n",
       "             scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "c4fdd3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'class_weight': {0: 1, 1: 5, 2: 1}, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(svm_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f5c0716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       705\n",
      "           1       0.56      0.33      0.41        73\n",
      "           2       0.95      0.93      0.94       805\n",
      "\n",
      "    accuracy                           0.92      1583\n",
      "   macro avg       0.80      0.74      0.76      1583\n",
      "weighted avg       0.91      0.92      0.91      1583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = svm_grid.predict(x_test)\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "1b5b5daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[677,  10,  18],\n",
       "       [ 30,  24,  19],\n",
       "       [ 46,   9, 750]], dtype=int64)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "47c78222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save\n",
    "with open('svm.pkl','wb') as f:\n",
    "    pickle.dump(svm_grid,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "1083fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svm.pkl', 'rb') as f:\n",
    "    svm = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "527b3d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       705\n",
      "           1       0.56      0.33      0.41        73\n",
      "           2       0.95      0.93      0.94       805\n",
      "\n",
      "    accuracy                           0.92      1583\n",
      "   macro avg       0.80      0.74      0.76      1583\n",
      "weighted avg       0.91      0.92      0.91      1583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = svm.predict(x_test)\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "8607bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_param_grid =  {  'alpha': [1, 0.1, 0.01, 0.001]  }  \n",
    "\n",
    "# nb_param_grid =  {  'var_smoothing': [1e-8, 1e-9, 1e-10]  }  \n",
    "nb_grid = GridSearchCV(nb_classifier, nb_param_grid, cv = 5, verbose = 3\n",
    "                        , scoring='f1_weighted')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "0324cc46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END ...........................alpha=1;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END ...........................alpha=1;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END ...........................alpha=1;, score=0.861 total time=   0.0s\n",
      "[CV 4/5] END ...........................alpha=1;, score=0.855 total time=   0.0s\n",
      "[CV 5/5] END ...........................alpha=1;, score=0.839 total time=   0.0s\n",
      "[CV 1/5] END .........................alpha=0.1;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END .........................alpha=0.1;, score=0.858 total time=   0.0s\n",
      "[CV 3/5] END .........................alpha=0.1;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=0.1;, score=0.863 total time=   0.0s\n",
      "[CV 5/5] END .........................alpha=0.1;, score=0.842 total time=   0.0s\n",
      "[CV 1/5] END ........................alpha=0.01;, score=0.862 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.01;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.01;, score=0.864 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.01;, score=0.858 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.01;, score=0.839 total time=   0.0s\n",
      "[CV 1/5] END .......................alpha=0.001;, score=0.859 total time=   0.0s\n",
      "[CV 2/5] END .......................alpha=0.001;, score=0.852 total time=   0.0s\n",
      "[CV 3/5] END .......................alpha=0.001;, score=0.861 total time=   0.0s\n",
      "[CV 4/5] END .......................alpha=0.001;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END .......................alpha=0.001;, score=0.835 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [1, 0.1, 0.01, 0.001]}, scoring='f1_weighted',\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "cd39d675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "586a77e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87       705\n",
      "           1       0.86      0.08      0.15        73\n",
      "           2       0.92      0.87      0.90       805\n",
      "\n",
      "    accuracy                           0.87      1583\n",
      "   macro avg       0.86      0.63      0.64      1583\n",
      "weighted avg       0.87      0.87      0.85      1583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = nb_grid.predict(x_test.toarray())\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "eabc8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nbayes.pkl','wb') as f:\n",
    "    pickle.dump(nb_grid,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "56a3e9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nbayes.pkl', 'rb') as f:\n",
    "    nb = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "38367314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8a8617d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 2}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a25d6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_params = {\"n_estimators\": [100,500,1000],\n",
    "          \"max_depth\": [10,50,100]}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_grid = GridSearchCV(estimator = rf, param_grid = rf_params, cv = 5, verbose = 3,\n",
    "                      scoring = \"f1_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "0f6e9efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END ....max_depth=10, n_estimators=100;, score=0.840 total time=   0.8s\n",
      "[CV 2/5] END ....max_depth=10, n_estimators=100;, score=0.834 total time=   0.8s\n",
      "[CV 3/5] END ....max_depth=10, n_estimators=100;, score=0.826 total time=   0.8s\n",
      "[CV 4/5] END ....max_depth=10, n_estimators=100;, score=0.836 total time=   0.8s\n",
      "[CV 5/5] END ....max_depth=10, n_estimators=100;, score=0.831 total time=   0.8s\n",
      "[CV 1/5] END ....max_depth=10, n_estimators=500;, score=0.842 total time=   4.6s\n",
      "[CV 2/5] END ....max_depth=10, n_estimators=500;, score=0.842 total time=   4.5s\n",
      "[CV 3/5] END ....max_depth=10, n_estimators=500;, score=0.832 total time=   4.4s\n",
      "[CV 4/5] END ....max_depth=10, n_estimators=500;, score=0.840 total time=   4.5s\n",
      "[CV 5/5] END ....max_depth=10, n_estimators=500;, score=0.832 total time=   4.2s\n",
      "[CV 1/5] END ...max_depth=10, n_estimators=1000;, score=0.845 total time=   8.8s\n",
      "[CV 2/5] END ...max_depth=10, n_estimators=1000;, score=0.849 total time=   8.4s\n",
      "[CV 3/5] END ...max_depth=10, n_estimators=1000;, score=0.836 total time=   8.8s\n",
      "[CV 4/5] END ...max_depth=10, n_estimators=1000;, score=0.841 total time=   8.7s\n",
      "[CV 5/5] END ...max_depth=10, n_estimators=1000;, score=0.829 total time=   9.1s\n",
      "[CV 1/5] END ....max_depth=50, n_estimators=100;, score=0.872 total time=   4.0s\n",
      "[CV 2/5] END ....max_depth=50, n_estimators=100;, score=0.877 total time=   4.0s\n",
      "[CV 3/5] END ....max_depth=50, n_estimators=100;, score=0.872 total time=   3.9s\n",
      "[CV 4/5] END ....max_depth=50, n_estimators=100;, score=0.873 total time=   4.1s\n",
      "[CV 5/5] END ....max_depth=50, n_estimators=100;, score=0.856 total time=   3.9s\n",
      "[CV 1/5] END ....max_depth=50, n_estimators=500;, score=0.873 total time=  20.5s\n",
      "[CV 2/5] END ....max_depth=50, n_estimators=500;, score=0.881 total time=  20.2s\n",
      "[CV 3/5] END ....max_depth=50, n_estimators=500;, score=0.876 total time=  20.0s\n",
      "[CV 4/5] END ....max_depth=50, n_estimators=500;, score=0.874 total time=  20.0s\n",
      "[CV 5/5] END ....max_depth=50, n_estimators=500;, score=0.861 total time=  20.0s\n",
      "[CV 1/5] END ...max_depth=50, n_estimators=1000;, score=0.872 total time=  39.3s\n",
      "[CV 2/5] END ...max_depth=50, n_estimators=1000;, score=0.879 total time=  42.0s\n",
      "[CV 3/5] END ...max_depth=50, n_estimators=1000;, score=0.876 total time=  40.9s\n",
      "[CV 4/5] END ...max_depth=50, n_estimators=1000;, score=0.874 total time=  39.4s\n",
      "[CV 5/5] END ...max_depth=50, n_estimators=1000;, score=0.862 total time=  38.3s\n",
      "[CV 1/5] END ...max_depth=100, n_estimators=100;, score=0.883 total time=   5.1s\n",
      "[CV 2/5] END ...max_depth=100, n_estimators=100;, score=0.887 total time=   5.2s\n",
      "[CV 3/5] END ...max_depth=100, n_estimators=100;, score=0.888 total time=   5.1s\n",
      "[CV 4/5] END ...max_depth=100, n_estimators=100;, score=0.883 total time=   5.2s\n",
      "[CV 5/5] END ...max_depth=100, n_estimators=100;, score=0.871 total time=   5.1s\n",
      "[CV 1/5] END ...max_depth=100, n_estimators=500;, score=0.882 total time=  26.8s\n",
      "[CV 2/5] END ...max_depth=100, n_estimators=500;, score=0.890 total time=  26.3s\n",
      "[CV 3/5] END ...max_depth=100, n_estimators=500;, score=0.888 total time=  26.3s\n",
      "[CV 4/5] END ...max_depth=100, n_estimators=500;, score=0.886 total time=  26.3s\n",
      "[CV 5/5] END ...max_depth=100, n_estimators=500;, score=0.870 total time=  26.3s\n",
      "[CV 1/5] END ..max_depth=100, n_estimators=1000;, score=0.883 total time= 1.0min\n",
      "[CV 2/5] END ..max_depth=100, n_estimators=1000;, score=0.891 total time= 1.1min\n",
      "[CV 3/5] END ..max_depth=100, n_estimators=1000;, score=0.891 total time= 1.0min\n",
      "[CV 4/5] END ..max_depth=100, n_estimators=1000;, score=0.888 total time= 1.0min\n",
      "[CV 5/5] END ..max_depth=100, n_estimators=1000;, score=0.871 total time=  57.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [10, 50, 100],\n",
       "                         'n_estimators': [100, 500, 1000]},\n",
       "             scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8ebc0b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       705\n",
      "           1       0.64      0.10      0.17        73\n",
      "           2       0.91      0.93      0.92       805\n",
      "\n",
      "    accuracy                           0.90      1583\n",
      "   macro avg       0.81      0.66      0.67      1583\n",
      "weighted avg       0.89      0.90      0.88      1583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = rf_grid.predict(x_test)\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "9a838720",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rf.pkl','wb') as f:\n",
    "    pickle.dump(rf_grid,f)\n",
    "\n",
    "with open('rf.pkl', 'rb') as f:\n",
    "    rf = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "ea22847d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, estimator=SVC(),\n",
      "             param_grid={'C': [0.1, 1, 10],\n",
      "                         'class_weight': [{0: 1, 1: 1, 2: 1},\n",
      "                                          {0: 1, 1: 5, 2: 1},\n",
      "                                          {0: 1, 1: 10, 2: 1}],\n",
      "                         'gamma': [1, 0.1, 0.01], 'kernel': ['linear', 'rbf']},\n",
      "             scoring='f1_weighted', verbose=3) GridSearchCV(cv=5, estimator=MultinomialNB(),\n",
      "             param_grid={'alpha': [1, 0.1, 0.01, 0.001]}, scoring='f1_weighted',\n",
      "             verbose=3) GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
      "             param_grid={'max_depth': [10, 50, 100],\n",
      "                         'n_estimators': [100, 500, 1000]},\n",
      "             scoring='f1_weighted', verbose=3)\n"
     ]
    }
   ],
   "source": [
    "print(svm, nb, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d15d3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "estimators = [svm, nb, rf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "71eb509f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96717493, 0.00513619, 0.02768888]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent = \n",
    "svm.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "25b167b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9179672  0.03260124 0.04943157]\n",
      " [0.87780261 0.01873761 0.10345978]\n",
      " [0.00290654 0.00283503 0.99425842]\n",
      " ...\n",
      " [0.89378641 0.02260848 0.08360511]\n",
      " [0.7191606  0.14020856 0.14063084]\n",
      " [0.27466275 0.08219859 0.64313866]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       705\n",
      "           1       0.64      0.29      0.40        73\n",
      "           2       0.94      0.94      0.94       805\n",
      "\n",
      "    accuracy                           0.92      1583\n",
      "   macro avg       0.83      0.73      0.76      1583\n",
      "weighted avg       0.91      0.92      0.91      1583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_pred = svm.predict_proba(x_test)\n",
    "nb_pred =  nb.predict_proba(x_test)\n",
    "rf_pred =  rf.predict_proba(x_test)\n",
    "\n",
    "average = (2 * svm_pred +   rf_pred)/(2  + 1)\n",
    "print(average)\n",
    "average = np.argmax(average, axis = 1)\n",
    "print(classification_report(y_test,average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "c320c5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87851074 0.0393866  0.08210267]\n",
      " [0.82048377 0.02094841 0.15856782]\n",
      " [0.00372661 0.00217068 0.99410271]\n",
      " ...\n",
      " [0.8686848  0.0265222  0.104793  ]\n",
      " [0.76272941 0.12525824 0.11201235]\n",
      " [0.39725914 0.08088688 0.52185397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       705\n",
      "           1       0.83      0.21      0.33        73\n",
      "           2       0.94      0.93      0.94       805\n",
      "\n",
      "    accuracy                           0.91      1583\n",
      "   macro avg       0.89      0.70      0.73      1583\n",
      "weighted avg       0.91      0.91      0.90      1583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_pred = svm.predict_proba(x_test)\n",
    "nb_pred =  nb.predict_proba(x_test)\n",
    "rf_pred =  rf.predict_proba(x_test)\n",
    "\n",
    "# Soft voting\n",
    "average = (2 * svm_pred + nb_pred + 2 * rf_pred)/(2 +1 + 2)\n",
    "print(average)\n",
    "average = np.argmax(average, axis = 1)\n",
    "print(classification_report(y_test,average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "32b7b084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11426x3449 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 102929 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "c26b2fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pred = svm.predict_proba(x_train)\n",
    "nb_pred =  nb.predict_proba(x_train)\n",
    "# rf_pred =  rf.predict_proba(x_train)\n",
    "\n",
    "stack_features = np.concatenate([svm_pred, nb_pred], axis = 1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg =  LogisticRegression()\n",
    "log_reg.fit(stack_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "71ed56dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       705\n",
      "           1       0.71      0.23      0.35        73\n",
      "           2       0.92      0.96      0.94       805\n",
      "\n",
      "    accuracy                           0.92      1583\n",
      "   macro avg       0.85      0.71      0.74      1583\n",
      "weighted avg       0.91      0.92      0.91      1583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_test = svm.predict_proba(x_test)\n",
    "nb_test =  nb.predict_proba(x_test)\n",
    "rf_test =  rf.predict_proba(x_test)\n",
    "\n",
    "stack_test = np.concatenate([svm_test, nb_test], axis = 1)\n",
    "\n",
    "test_predictions = log_reg.predict(stack_test)\n",
    "print(classification_report(y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "15a42c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [{0:1, 1: 1, 2:1}, {0:1, 1:5, 2:1}, {0:1, 1:10, 2:1}]\n",
    "# param_grid = {'C': [0.1, 1, 10],\n",
    "#               'gamma': [ 1],\n",
    "#               'kernel': ['linear', 'rbf'],\n",
    "#              'class_weight': weights}\n",
    "\n",
    "\n",
    "# param_grid = {'C': [1],\n",
    "#               'gamma': [ 1],\n",
    "#               'kernel': ['rbf'],\n",
    "#              'class_weight': [{0:1, 1:5, 2:1}]}\n",
    "\n",
    "\n",
    "svm_classifier = SVC(C = 1, gamma = 1, kernel = 'rbf', class_weight = {0:1, 1:5, 2:1}, probability =True)\n",
    "\n",
    "# svm_grid = GridSearchCV(svm_classifier, param_grid, cv = 5, verbose = 3\n",
    "#                         , scoring='f1_weighted')\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB(alpha = 0.1)\n",
    "\n",
    "# nb_param_grid =  {  'alpha': [1, 0.1, 0.01, 0.001]  }  \n",
    "\n",
    "# nb_param_grid =  {  'var_smoothing': [1e-8, 1e-9, 1e-10]  }  \n",
    "# nb_grid = GridSearchCV(nb_classifier, nb_param_grid, cv = 5, verbose = 3\n",
    "#                         , scoring='f1_weighted')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "61a5b486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.fit(x_train, y_train)\n",
    "nb_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "e22e4cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('svm',svm_classifier), ('nb',nb_classifier)]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), \n",
    "                         stack_method = 'predict_proba', passthrough = \"True\", verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "7981968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   49.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "C:\\Users\\Dung\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('svm',\n",
       "                                SVC(C=1, class_weight={0: 1, 1: 5, 2: 1},\n",
       "                                    gamma=1, probability=True)),\n",
       "                               ('nb', MultinomialNB(alpha=0.1))],\n",
       "                   final_estimator=LogisticRegression(), passthrough='True',\n",
       "                   stack_method='predict_proba', verbose=3)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "0d45ca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       705\n",
      "           1       0.57      0.32      0.41        73\n",
      "           2       0.94      0.95      0.94       805\n",
      "\n",
      "    accuracy                           0.92      1583\n",
      "   macro avg       0.81      0.74      0.76      1583\n",
      "weighted avg       0.91      0.92      0.91      1583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(x_test)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641421ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingEnsemble(models, x_train):\n",
    "    models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "aa6e1103",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'GridSearchCV' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1692/1159778569.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msoft_voting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'soft'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msoft_voting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;34m\"\"\"Get common fit operations.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[1;34m\" of (string, estimator) tuples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             )\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[1;31m# defined by MetaEstimatorMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'GridSearchCV' object is not iterable"
     ]
    }
   ],
   "source": [
    "soft_voting = VotingClassifier(estimators=estimators,voting='soft')\n",
    "\n",
    "soft_voting.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9bd74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
